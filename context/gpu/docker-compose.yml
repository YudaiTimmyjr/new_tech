version: "3.9"
services:
  dev:
    image: ${PROJECT}:${SANITIZED_USER}_${USER_UID}
    container_name: ${PROJECT}_${SANITIZED_USER}_${USER_UID}

    build:
      context: ../../context/
      dockerfile: Dockerfile
      args:
        BASE_IMAGE: nvidia/cuda:12.2.2-cudnn8-devel-ubuntu20.04
        USERNAME: ${USER}
        USER_UID: ${USER_UID}
        PYTHON_MAJOR_VERSION: 3
        PYTHON_MINOR_VERSION: 12
        PYTHON_PATCH_VERSION: 11
        UV_VERSION: 0.8.19

    volumes:
      - type: bind
        source: ${PARENT_DIR}/${PROJECT_DIR}
        target: /home/${USER}/${PROJECT_DIR}
      - type: bind
        source: ${HOME}/.ssh
        target: /home/${USER}/.ssh
      - type: bind
        source: ${HOME}/.gitconfig
        target: /home/${USER}/.gitconfig

    # ports: 
    #   - '8888:8888'

    working_dir: /home/${USER}/${PROJECT_DIR}
    tty: true

    # runtime: nvidia
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [ gpu ]

    environment:
      - NVIDIA_VISIBLE_DEVICES=all
      - NVIDIA_DRIVER_CAPABILITIES=utility,compute
      - UV_CACHE_DIR=/home/${USER}/${PROJECT_DIR}/.cache/uv
      - HF_HOME=/home/${USER}/${PROJECT_DIR}/.cache/huggingface
      - WANDB_CACHE_DIR=/home/${USER}/${PROJECT_DIR}/.cache/wandb
      - TORCH_HOME=/home/${USER}/${PROJECT_DIR}/.cache/torch
      
    restart: always
    shm_size: '16gb'
    command: /bin/bash
    ulimits:
      memlock: -1
