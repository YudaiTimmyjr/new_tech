# LLMの因果・相関関係の多言語評価

## 概要

本リポジトリは、LLMが自然言語で記述されたシナリオから**因果関係（Causality）**と**相関関係（Correlation）**を正確に区別し、さらに詳細な因果構造を推論する能力を評価するために実施された実験）に関するものです。

この評価は、**Zhijing Jin et al., 2024**による論文「**Can Large Language Models Infer Causation from Correlation?**」（arXiv:2306.05836）を参考にし、その課題意識を多言語の**gpt-5-chat**モデルで検証しました。

## 評価背景と目的 (Causal NLP)

LLMの基礎的な推論能力の限界を探る、因果的自然言語処理（Causal NLP）という最先端の研究領域の一部として認識されています。

### 引用・参照論文

**Can Large Language Models Infer Causation from Correlation?** (Zhijing Jin et al., 2024)
*   **arXivリンク**: https://arxiv.org/pdf/2306.05836

### 評価の焦点

この引用論文の研究目的は、LLMの因果能力を、単なる**経験的知識**（常識や学習データから得た知識）としてではなく、**純粋な因果推論**（既知の手続きや形式的ルール、例えばSpirtes 2000などに基づいた論理的な導き）として評価することができるかを明らかにすることです。

*   先行研究の多くは因果推論を経験的知識の延長として捉えており、学習データの質やカバレッジに依存していました。
*   本研究が問うているのは、与えられた相関関係のルールのみを頼りに、LLMが**論理的に因果関係を導き出せるか**という点です。

### LLMの推論能力に関する先行研究の知見

引用論文では、LLMの推論能力の一側面である純粋な因果推論を探るため、評価データセット **CORR2CAUSE**が定義・作成されています。

*   **Fine Tuning前の能力**: 最も性能が良かったモデル（BART MNLI）でもF1スコアは**33.38%**であり、純粋な因果推論能力はほぼ無いと結論付けられています。
*   **Fine Tuning後の限界**: Fine Tuningによって性能は大幅に向上するものの、その効果は学習したデータと同じ種類のデータ（分布内、in-distribution）に対して限定的でした。特に、**分布外一般化の問題**が依然として残ることが分かっています（例: 訓練データの「氷と水の相関」の例に対し、テストデータで「インターネット利用と健康問題の相関」など、新しい分野の因果関係を推論できない）。

## 評価タスクと手法

本評価では、因果関係と相関関係を区別するために、以下の6種類のゴールドラベルを含む50問のシナリオ（日本語、英語、ロシア語）に基づいて、4つのタスクを定義しました。

*   **因果タイプ（4分類）**: `Is-Parent` (直接原因), `Is-Ancestor` (間接原因), `Is-Child` (直接結果), `Is-Descendant` (間接結果)。
*   **相関タイプ（2分類）**: `Has-Collider` (共通の結果), `Has-Confounder` (共通の原因)。

| タスク名 | 入力情報 | 出力ラベル | 狙い/評価指標 |
| :--- | :--- | :--- | :--- |
| **タスク1** (Scenario-only) | シナリオ（文章）のみ | Causal / Correlational / Other (3分類) | 文のトーンや構造からの関係種別の識別能力。 |
| **タスク2** (Keyword Extraction) | シナリオ（文章） | 最も重要な2つの名詞句 (変数 i, j) | 変数（キーワード）の抽出能力。 |
| **タスク3** (3分類) | 変数 i, j | Causal / Correlational / Other (3分類) | 変数が明示された状態での論理関係の理解度。
| **タスク4** (4分類) | 変数 i, j | Is-Parent / Is-Ancestor / Is-Child / Is-Descendant | 詳細な因果構造（直接/間接）を区別する能力。

※タスク3と4には、正解のキーワードを使用する**Oracle**評価と、タスク2で抽出したキーワードを使用する**E2E**（End-to-End）評価の2種類があります。


## 使用モデルと環境

本評価では、以下の2つのモデルを用いています。

| 項目 | 詳細 |
| :--- | :--- |
| **評価モデル** | Gemini 2.5 Pro、gpt-5-chat |
| **評価言語** | 日本語、英語、ロシア語 |

## 実行結果 (Gemini 2.5 Pro / gpt-5-chat)

両モデルを3言語で実行した結果は以下の通りです。

### 1. 日本語の結果 (総問題数: 50, タスク4対象: 34問)

| モデル | Task 1 | Task 2 | Task 3 (Oracle) | Task 3 (E2E) | Task 4 (Oracle) | Task 4 (E2E) |
| :--- | :--- | :--- | :--- | :--- | :--- | :--- |
| **Gemini 2.5 Pro** | **100.00%** | **36.00%** | 66.00% | **84.00%** | **70.59%** | **47.06%** |
| **GPT-5 Chat** | 96.00% | 30.00% | **94.00%** | 70.00% | 55.88% | 41.18% |


### 2. 英語の結果 (総問題数: 50, タスク4対象: 34問)

| モデル | Task 1 | Task 2 | Task 3 (Oracle) | Task 3 (E2E) | Task 4 (Oracle) | Task 4 (E2E) |
| :--- | :--- | :--- | :--- | :--- | :--- | :--- |
| **Gemini 2.5 Pro** | **100.00%** | 4.00% | 66.00% | **78.00%** | **73.53%** | 38.24% |
| **GPT-5 Chat** | 92.00% | **20.00%** | **94.00%** | 64.00% | 58.82% | 38.24% |

### 3. ロシア語の結果 (総問題数: 50, タスク4対象: 34問)

| モデル | Task 1 | Task 2 | Task 3 (Oracle) | Task 3 (E2E) | Task 4 (Oracle) | Task 4 (E2E) |
| :--- | :--- | :--- | :--- | :--- | :--- | :--- |
| **Gemini 2.5 Pro** | 98.00% | 2.00% | 76.00% | **72.00%** | 67.65% | **41.18%** |
| **GPT-5 Chat** | 88.00% | **16.00%** | **88.00%** | 68.00% | 58.52% | 41.18% |


## 考察及び主な発見

両モデルの比較と先行研究の考察から、以下の重要な知見が得られました 。

1.  **キーワード抽出の難しさと論理理解のギャップ**:
    *   タスク2（キーワード抽出）の正答率が低いにもかかわらず、タスク3（論理関係の理解）のE2E正答率が高いという結果は、LLMが**形式的な変数抽出（短い名詞句）**は得意ではないものの、文章の文脈から**論理関係の区別自体はできる**ようになったことを示唆しています 。
2.  **モデル間の特性の違い**:
    *   **Gemini 2.5 Pro**は、キーワード抽出（Task 2）はGPT-5よりも得意ではない傾向があるものの、一段階難しくなる**論理関係の理解（Task 3 E2E）**においてはGPTよりも得意であることが示されました 。特に**日本語理解能力は Geminiの方が高い**と結論付けられています 。
    *   **GPT-5 Chat**は、正解のキーワードが与えられた状態であれば、タスク3で非常に高い精度を示し、概ね論理関係を理解できます 。
3.  **因果構造の詳細な識別は依然として困難**:
    *   タスク4（因果タイプ四分類、例: 直接原因か間接原因か）のE2Eスコアは、どのモデル、どの言語でも47.06%以下にとどまっており、**因果関係の中の区別という作業は、まだ実用できるレベルではない**と評価されました。
4.  **一般化能力の問題**:
    *   先行研究と同様に、LLMがファインチューニングによって獲得できる効果は、学習したデータと同じ種類のデータ（分布内）に対して限定的であり、**分布外一般化 (out-of-distribution generalization) の問題は依然として残る**という課題が改めて強調されました。

本実験結果やコードの全部または一部を引用、再利用、あるいは商業的にご検討の場合は、適切な権利帰属および利用条件の確認のため、お手数ですが以下の連絡先までご連絡をお願いいたします。

アカデミア利用の場合は、引用していただけたら問題ありません。

連絡先: mayhawks9@gmail.com